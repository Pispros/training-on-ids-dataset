# DÃ©tection d'Intrusions RÃ©seau par Apprentissage Automatique

Ce dÃ©pÃ´t contient l'implÃ©mentation et l'Ã©valuation de diffÃ©rentes mÃ©thodes d'apprentissage automatique pour la dÃ©tection d'intrusions rÃ©seau sur trois datasets de rÃ©fÃ©rence : KDD CUP, UNSW-NB15 et CICIDS2018.

## ğŸ“‹ Vue d'ensemble

L'objectif de ce projet est d'Ã©valuer et de comparer l'efficacitÃ© de diffÃ©rentes approches de machine learning pour la dÃ©tection d'intrusions rÃ©seau:
- EntraÃ®nement classique avec des algorithmes standards
- Optimisation des hyperparamÃ¨tres avec Hyperopt
- MÃ©thodes d'apprentissage en contexte (In-Context Learning) avec TabPFN et TabICL

Chaque mÃ©thode est testÃ©e sur trois datasets diffÃ©rents avec plusieurs seeds pour garantir la robustesse des rÃ©sultats.

## ğŸ” Datasets

### KDD CUP
- Benchmark classique pour la dÃ©tection d'intrusion
- Ã‰valuations avec 10 seeds diffÃ©rentes

### UNSW-NB15
- Dataset moderne contenant des trafics rÃ©seau normaux et d'attaque
- Ã‰valuations sur 4 fichiers diffÃ©rents avec 5 seeds pour chacun

### CICIDS2018
- Dataset rÃ©cent couvrant diverses catÃ©gories d'attaques
- Ã‰valuations sur 10 fichiers diffÃ©rents avec 5 seeds pour chacun
- Tests supplÃ©mentaires de prÃ©vision de sÃ©ries temporelles (rÃ©gression)

## ğŸ§ª MÃ©thodologie

Pour chaque dataset, nous avons appliquÃ© trois phases d'expÃ©rimentation:

1. **EntraÃ®nement classique**
   - Utilisation d'algorithmes standards de machine learning
   - Ã‰valuation des performances de base

2. **Optimisation des hyperparamÃ¨tres**
   - Utilisation de Hyperopt pour optimiser les modÃ¨les
   - Recherche automatisÃ©e des meilleurs hyperparamÃ¨tres

3. **MÃ©thodes ICL (In-Context Learning)**
   - ImplÃ©mentation de TabPFN (Prior-Data Fitted Networks)
   - ImplÃ©mentation de TabICL (Tabular In-Context Learning)
   - Ã‰valuation des performances sans entraÃ®nement explicite

4. **TÃ¢che de rÃ©gression**
   - PrÃ©vision de sÃ©ries temporelles sur CICIDS2018
   - MÃ©triques de performance spÃ©cifiques Ã  la rÃ©gression

## ğŸ“Š Structure des expÃ©riences

- **KDD CUP**: 10 seeds Ã— 3 phases (entraÃ®nement, hyperopt, TabPFN/TabICL)
- **UNSW-NB15**: 5 seeds Ã— 4 fichiers Ã— 3 phases
- **CICIDS2018**: 5 seeds Ã— 10 fichiers Ã— 3 phases + tÃ¢che de rÃ©gression

## ğŸ“ Structure du dÃ©pÃ´t

```
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ kdd_cup/
â”‚   â”‚   â”œâ”€â”€ classic_training/
â”‚   â”‚   â”œâ”€â”€ hyperopt_optimization/
â”‚   â”‚   â”œâ”€â”€ icl_methods/
â”‚   â”‚   â”‚   â”œâ”€â”€ tabpfn/
â”‚   â”‚   â”‚   â””â”€â”€ tabicl/
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”œâ”€â”€ unsw_nb15/
â”‚   â”‚   â”œâ”€â”€ classic_training/
â”‚   â”‚   â”œâ”€â”€ hyperopt_optimization/
â”‚   â”‚   â”œâ”€â”€ icl_methods/
â”‚   â”‚   â”‚   â”œâ”€â”€ tabpfn/
â”‚   â”‚   â”‚   â””â”€â”€ tabicl/
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”œâ”€â”€ cicids2018/
â”‚   â”‚   â”œâ”€â”€ classic_training/
â”‚   â”‚   â”œâ”€â”€ hyperopt_optimization/
â”‚   â”‚   â”œâ”€â”€ icl_methods/
â”‚   â”‚   â”‚   â”œâ”€â”€ tabpfn/
â”‚   â”‚   â”‚   â””â”€â”€ tabicl/
â”‚   â”‚   â”œâ”€â”€ time_series/
â”‚   â”‚   â””â”€â”€ results/
â”‚   â””â”€â”€ notebooks/
â”‚       â”œâ”€â”€ kdd_cup.ipynb
â”‚       â”œâ”€â”€ unsw_nb15.ipynb
â”‚       â””â”€â”€ cicids2018.ipynb
â””â”€â”€ preprocessor/
    â”œâ”€â”€ kdd_preprocessor.py
    â”œâ”€â”€ unsw_preprocessor.py
    â”œâ”€â”€ cicids_preprocessor.py
    â”œâ”€â”€ utils.py
    â””â”€â”€ visualization.py
```

## ğŸš€ Installation et utilisation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/Pispros/training-on-ids-dataset
cd detection-intrusion-ml

# Installer les dÃ©pendances
pip install -r requirements.txt

# ExÃ©cuter les notebooks
jupyter notebook notebooks/
```

## ğŸ“” Notebooks

Les notebooks Colab contiennent l'implÃ©mentation complÃ¨te et les rÃ©sultats des expÃ©riences:

- [KDD CUP Notebook](https://colab.research.google.com/drive/1JvMTkVgEu2awt2IBXOWV9z33LMN15Z43?usp=sharing)
- [UNSW-NB15 Notebook](https://colab.research.google.com/drive/1-5vDR73L9d_qvdWXx4qCxcQudkIcWSWY?usp=sharing)
- [CICIDS2018 Notebook](https://colab.research.google.com/drive/1mz_lpUrGve69-umgS82PYYAJ0nY7gpWo?usp=sharing)

## ğŸ“ˆ RÃ©sultats principaux

### KDD CUP
- RÃ©sumÃ© des performances sur 10 seeds
- Comparaison entre les approches classiques et ICL

### UNSW-NB15
- RÃ©sultats sur les 4 fichiers diffÃ©rents
- Impact de l'optimisation des hyperparamÃ¨tres

### CICIDS2018
- Performances Ã  travers les 10 fichiers
- Analyse des rÃ©sultats de prÃ©vision de sÃ©ries temporelles

### Lien Drive vers les rÃ©sultats
<img src="https://ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png" width="16" height="16" /> [Lien Google Drive](https://drive.google.com/drive/folders/17WC3Tv17FralhxkWiMLdcqUzndMXmB4k?usp=sharing)

## ğŸ”§ Technologies utilisÃ©es

- Python
- Scikit-learn
- Hyperopt
- TabPFN
- TabICL
- Pandas, NumPy
- Matplotlib, Seaborn
